{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 : Bioinformatics Stronghold: \n",
    "## Assignment: Dec 4th with Dynamic Programming\n",
    "# first fill DP array\n",
    "# theb find the maximum value in dp and its index\n",
    "# then reconstruct the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 159 212 323 377 387 463 466 485 557 581 585 634 672 714 735 736 797 850 869 878 889 942 953 992 1014 1016 1052 1078 1123 1126 1134 1139 1149 1357 1376 1402 1437 1441 1495 1509 1528 1530 1566 1575 1638 1772 1849 1850 1854 1918 1988 2010 2019 2112 2136 2164 2215 2302 2305 2415 2417 2562 2603 2633 2640 2716 2737 2791 2817 2819 2853 2929 3027 3053 3281 3346 3435 3483 3523 3572 3600 3696 3762 3797 3892 3941 3942 4066 4127 4140 4242 4258 4331 4456 4495 4573 4580 4788 4822 4834 4842 4869 4891 4892 4931 5002 5051 5110 5117 5167 5195 5221 5223 5264 5271 5280 5339 5390 5410 5483 5609 5659 5702 5722 5733 5754 5764 5792 5811 5824 5837 5851 5853 5928 5965 6003 6021 6103 6137 6152 6297 6315 6333 6383 6411 6435 6473 6585 6596 6641 6716 6726 6782 6851 6856 6948 6983 7000 7121 7128 7213 7266 7284 7314 7385 7592 7601 7696 7714 7868 7954 7973 8076 8184 8188 8205 8221 8242 8245\n",
      "8297 8281 8278 8259 8231 8161 8158 8153 8147 8134 8116 8059 8029 7896 7886 7833 7822 7771 7721 7709 7685 7667 7635 7632 7608 7495 7475 7452 7441 7420 7418 7331 7327 7311 7244 7113 7046 7008 7001 6996 6937 6880 6847 6806 6633 6531 6319 6271 6253 6200 6133 6001 5974 5865 5846 5841 5821 5783 5757 5729 5705 5704 5671 5634 5528 5464 5445 5431 5397 5356 5314 5300 5276 5233 5215 5083 5055 5039 5025 5014 5011 4870 4859 4834 4809 4768 4737 4695 4650 4643 4599 4578 4520 4448 4434 4423 4415 4355 4278 4276 4227 4161 4008 3990 3850 3846 3741 3738 3675 3658 3633 3607 3605 3563 3427 3399 3374 3313 3298 3262 3224 3162 3159 3155 3102 3094 3072 3039 2696 2682 2680 2634 2558 2550 2545 2491 2410 2268 2206 2080 2051 1881 1828 1771 1712 1693 1642 1598 1245 1163 1093 1067 1064 1046 941 921 913 813 754 687 670 664 627 558 482 415 382 347 185 94 46 37\n"
     ]
    }
   ],
   "source": [
    "# Lgis (Longest Increasing Subsequence)\n",
    "# first part of DP : LIS Function: To find the Longest Increasing Subsequence\n",
    "# DP array to store LIS *lengths* and then it has to To reconstruct it\n",
    "# the I have to fill the array\n",
    "# find the maximum value in dp and its index\n",
    "# in order to get the correct order reverse it\n",
    "# Reconstruct the sequence using max sequence\n",
    "\n",
    "## (filling the DP array, finding the max index, and reconstructing the sequence.)\n",
    "\n",
    "# two inputs, number of elements then sequence of numbers\n",
    "with open('rosalind_lgis.txt') as f:\n",
    "    n = int(f.readline())  \n",
    "    numbers = list(map(int, f.readline().strip().split())) \n",
    "\n",
    "\n",
    "def lis(arr):\n",
    "    n = len(arr)\n",
    "    dp = [1] * n \n",
    "    predecessor = [-1] * n \n",
    "\n",
    "    # Fill the DP array\n",
    "    for i in range(1, n):\n",
    "        for j in range(i):\n",
    "            if arr[i] > arr[j] and dp[i] < dp[j] + 1:\n",
    "                dp[i] = dp[j] + 1\n",
    "                predecessor[i] = j\n",
    "\n",
    "    max_index = dp.index(max(dp))\n",
    "\n",
    "    lis_seq = []\n",
    "    while max_index != -1:\n",
    "        lis_seq.append(arr[max_index])\n",
    "        max_index = predecessor[max_index]\n",
    "\n",
    "    return lis_seq[::-1] \n",
    "\n",
    "# LDS Function: To find the Longest Decreasing Subsequence\n",
    "def lds(arr):\n",
    "    n = len(arr)\n",
    "    dp = [1] * n \n",
    "    predecessor = [-1] * n  \n",
    "\n",
    "    for i in range(1, n):\n",
    "        for j in range(i):\n",
    "            if arr[i] < arr[j] and dp[i] < dp[j] + 1:\n",
    "                dp[i] = dp[j] + 1\n",
    "                predecessor[i] = j\n",
    "\n",
    "    # Find the maximum value in dp and its index\n",
    "    max_index = dp.index(max(dp))\n",
    "\n",
    "    # Reconstruct the sequence\n",
    "    lds_seq = []\n",
    "    while max_index != -1:\n",
    "        lds_seq.append(arr[max_index])\n",
    "        max_index = predecessor[max_index]\n",
    "\n",
    "    return lds_seq[::-1]  # Reverse to get the correct order\n",
    "\n",
    "lis_seq = lis(numbers)\n",
    "lds_seq = lds(numbers)\n",
    "\n",
    "print(' '.join(map(str, lis_seq)))  # Longest *Increasing* Subsequence\n",
    "print(' '.join(map(str, lds_seq)))  # Longest *Decreasing* Subsequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3 12 17 18 22 26 32 38 42 43 46 48 54 62 64 65 67 76 79 87 88 90 92 94 99 101 105 109 111 118 125 135 137 143 144 147 148 158 164 173 182 184 199 203 205 208 211 215 217 222 228 229 230 231 233 239 242 247 250 251\n"
     ]
    }
   ],
   "source": [
    "# sseq (Finding a Spliced Motif)\n",
    "#  Extract DNA string (s) and motif (t)\n",
    "# Find motif positions\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "with open('rosalind_sseq.txt') as f:\n",
    "    records = list(SeqIO.parse(f, \"fasta\"))\n",
    "    s = str(records[0].seq)\n",
    "    t = str(records[1].seq)\n",
    "\n",
    "position = 0\n",
    "log = []\n",
    "\n",
    "for i in t:\n",
    "    index = s[position:].find(i)\n",
    "    if index == -1:\n",
    "        raise ValueError(f\"Motif character '{i}' not found in the DNA sequence.\")\n",
    "    position += index + 1\n",
    "    log.append(position)\n",
    "\n",
    "print(\" \".join(map(str, log)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCCCGACCAAGACGAGTACGATTAACTAGAAATGTTCAACTTCCCCGGGCGCCTATCCCAATACGCTCGAGCTCAGAGGGAGACACAGGCACTGGTAATGTTGGGTTCGACCCGCGCATACTGCTTTTTGCATCTCTCCATAGAGGATGTTCGACATTATAGTTGCCAACCGGCTTGCATACATCTGTGAGCATGGGTTTCGATCCTCGGGTTGAGCGACATGGTTCAATGTCAAGAACGATTAAACATTGACGGTTACTAGTAAAAGTCATGCCCCGCCGGCCTTCGGCAGCAAACTAATAACCCGGAGGGCCCTTGCAGTCAACAAACGCCTGCCAGACTCCATTCCACCCGGAGGGGAGTATATAAAACGTTGCGAAAACGCAATTTGAGAGGAGCACCCCATGTCCACTCTATGTCCGCAAGTCAGAACCTACTGGTGAGGATTACGCTGGGCTTCATCTTTATTAAATTCCTTGATGTGCCTGGAGCGCATCCGAATTACAGACTTAAGCTCTAAACTAAACGACGGGTAACGCCGGGAAACTCTCCAACAGTGCAGGTTTCGTCAAACGGTGTTTGGCTGGCAAGTCACCAATCGGCCTCAGAAAAGGTTTAGGAAAGCAG\n"
     ]
    }
   ],
   "source": [
    "# Finding a Shared Spliced Motif using Dynamic Programming\n",
    "# Find the longest common subsequence by backtracking , reversing \n",
    "# Locating Motifs Despite Introns\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Read the input file and extract two DNA sequences\n",
    "with open(\"rosalind_lcsq.txt\", \"r\") as fa:\n",
    "    seq_name, seq_string = [], []\n",
    "    for seq_record in SeqIO.parse(fa, \"fasta\"):\n",
    "        seq_name.append(seq_record.name)\n",
    "        seq_string.append(str(seq_record.seq))\n",
    "    s, t = seq_string\n",
    "\n",
    "m, n = len(s), len(t)\n",
    "dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
    "\n",
    "for i in range(m):\n",
    "    for j in range(n):\n",
    "        if s[i] == t[j]:\n",
    "            dp[i + 1][j + 1] = 1 + dp[i][j]\n",
    "        else:\n",
    "            dp[i + 1][j + 1] = max(dp[i + 1][j], dp[i][j + 1])\n",
    "\n",
    "\n",
    "longest_common_subsequence = []\n",
    "while m != 0 and n != 0:\n",
    "    if dp[m][n] == dp[m - 1][n]:\n",
    "        m -= 1\n",
    "    elif dp[m][n] == dp[m][n - 1]:\n",
    "        n -= 1\n",
    "    else:\n",
    "        longest_common_subsequence.append(s[m - 1])\n",
    "        m -= 1\n",
    "        n -= 1\n",
    "        \n",
    "print(\"\".join(reversed(longest_common_subsequence)))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n"
     ]
    }
   ],
   "source": [
    "# Edit Distance\n",
    "# Point Mutations Include Insertions and Deletions\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Extract DNA strings (s) and (t)\n",
    "# Import via using Fasta file formatting\n",
    "# Get 2 protein strings\n",
    "\n",
    "seq_name, seq_string = [], []\n",
    "\n",
    "with open(\"rosalind_edit.txt\", \"r\") as fa:\n",
    "    for seq_record in SeqIO.parse(fa, \"fasta\"):\n",
    "        seq_name.append(seq_record.name)\n",
    "        seq_string.append(str(seq_record.seq))\n",
    "\n",
    "# Extract only the first two sequences \n",
    "# otherwise I'll get an error !! \n",
    "s, t = seq_string[:2]\n",
    "\n",
    "def EditDistance(s, t):\n",
    "    n = len(s)\n",
    "    m = len(t)\n",
    "\n",
    "    D = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "    \n",
    "    # this is the base case\n",
    "    for i in range(n + 1):\n",
    "        D[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        D[0][j] = j\n",
    "    \n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            left = D[i - 1][j] + 1\n",
    "            down = D[i][j - 1] + 1\n",
    "            left_down = D[i - 1][j - 1]\n",
    "            if s[i - 1] != t[j - 1]:\n",
    "                left_down += 1\n",
    "            D[i][j] = min(left, down, left_down)\n",
    "    return D[n][m]\n",
    "\n",
    "print(EditDistance(s, t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n",
      "KSSHWRGDHAHVV----EGHAHQDLRLVEWYCC-------NAYGK----NPEP--DCHIHCWYKNMMKALFHMWCYVPPQQAS---PVM---LNQVFSQGCCGTSPRCDSSSGWINHMFMVLYQVRFCTTWKAGNICEEPC-V----EEFKTEYVVWRNDN-RNL----AMTDQEKKRDGA-----EPQFSGFPKCPLYWGWWFHDRTAPEARMMPTENCCYAPHTFDYKDTNQWPAKNGDRPWPKMWMPIMIWADKYVSKSVCHASRWIYSVPCCFNRLEMFSNHNRQMNSCGYVKRLQWNPYECAVELYFHVSMPCA-QRAFGGDGKGKLLRQKGAILWWQHFM-----GIASVQECKHNHQPVYCRGNGTNQIFEGMCHRDDPVG------LSNWWWSWVFCVVVDVWGA---KENWRMCMLILHDD-DWQHLHGETP-MKNLS-FAMFPHSIFLFTSKLWNMVVVYPAISCEETPRCTEEFVDQARGMWCWGSRSKY-KKQQNK-FDDH--MKTRYHMHKSISVHCALYARWR-------YDS-G-----LFCVNDALLINGGLVKTWIVCQRTPYFGSFCVQIWKVCEAIMTDNLDVCR-YIAV---NQR---RDFENDHWKQYSSQMILQPGQDCHLPMNDNAPYNEPWWDPDLFYEGEVLCRQPNMQNGNCMMNHEIAVTELSGAEQHYQND--YQRGYIDKGANIYINI-VPDDHHTGFIVEMLMHMQ--P--RDTMILW---Q--HWH--IPRNGKKNDKHAYNLGMGDHSQACELCHVHNSACYRGDHSRYLMPCCCVGPCWLNSMMQVCAW-------EGAGKWIKIIGKKWCCNYVTMICTIQWSYCVSI\n",
      "KSSHWRGDHAIVVTQLPPGHAHQDLRLVEWYCCTWQVKIMIAYGKHMESWPEPYYTCHIHVWYKNMMLALFHMWDYVLPQQASFQAQAMQFALNQPF-CGTKMQWPR-DSSSGWINH---QL-CVKLFFYWKAGNICEEPCTVYMFIFVFKTEYVVWSNMNCYQLCDQKFCTLTMKKRDGACYFFSVPQFSGFPKCPLYWGWWFHDRTAPEARMMPTENCCYAPHTFDYKDTNQWPAKN----WPKMWMPIMIW-PTMHFKYV---SPWIYSVPCC------F-NHNRQHNSCGYVLRLQWNHYECTAFFVCETSMSCAWITAFGGDGKGKLLRWKGAILTWQHFMWIWTQGVQSVQECAHNHQPVYCRRNGMNQIFEGMCHFDDFVGSQRDHETSNWWWCVVFQGVYRKFAAFVPWENWRMC----HDDTYCVKRYYSTPSAKNLSHAAVFPHSIFLFTS-NAQFERPSPAISC-E--RCTEEFVDTARGMWCWGSRSKYRQAAVGKQMKDHMMMICVPIGIFFISVHIAHYARSRVIVTAEQGMSGGDEPMSHFCVVDALLINSGLVKTWIVCQRTPYWGQTCVQIWKVMEAIMTDNLDVCRSAVMVGRLIQRQNSFDFENDHWKNYSSQMILIPGDDCHL--------------P-LEYEGEQLCRQPNMQNGNCMMTHEIAVTEMSVAEQHYQLDAETQRGYIDKGASHYINIEGGFMFFESFIVEMLMHMQDDPIIRDTMILWECHQNHHWHWMIPRHGKK--FSRY-LGMGDHSQACELYHVHNSACYRGDHSRY---------CWLNS-MQVCAWKQLTFFRLGAGKWFYVCDKKWVCN-VTMICTIQQDYCVKI\n"
     ]
    }
   ],
   "source": [
    "# (editA) Edit Distance Alignment\n",
    "# Reconstructing Edit Distance\n",
    "# Here I have to match function for edit distance\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "def match(a, b):\n",
    "    return 0 if a == b else 1\n",
    "\n",
    "# import sequences from as a fasta file\n",
    "seqs = [] # initialize \n",
    "with open('rosalind_edta.txt', 'r') as f:\n",
    "    for record in SeqIO.parse(f, 'fasta'):\n",
    "        seqs.append(str(record.seq))\n",
    "\n",
    "s, t = seqs[0], seqs[1]\n",
    "\n",
    "# use dynamic programming so use a base case and fill the table\n",
    "M = [[0 for _ in range(len(t) + 1)] for _ in range(len(s) + 1)]\n",
    "\n",
    "for i in range(1, len(s) + 1):\n",
    "    M[i][0] = i\n",
    "for i in range(1, len(t) + 1):\n",
    "    M[0][i] = i\n",
    "\n",
    "for i in range(1, len(s) + 1):\n",
    "    for j in range(1, len(t) + 1):\n",
    "        cost = 0 if s[i-1] == t[j-1] else 1\n",
    "        M[i][j] = min(M[i-1][j] + 1, M[i][j-1] + 1, M[i-1][j-1] + cost)\n",
    "\n",
    "print(M[len(s)][len(t)])\n",
    "\n",
    "# Reconstructing , allignment\n",
    "s_prim, t_prim = '', '' # initialize before going in the loop\n",
    "i, j = len(s), len(t)\n",
    "\n",
    "while i * j != 0:\n",
    "    if M[i][j] == M[i-1][j-1] + match(s[i-1], t[j-1]):\n",
    "        s_prim = s[i-1] + s_prim\n",
    "        t_prim = t[j-1] + t_prim\n",
    "        i -= 1\n",
    "        j -= 1\n",
    "    elif i > 0 and M[i][j] == M[i-1][j] + 1:\n",
    "        s_prim = s[i-1] + s_prim\n",
    "        t_prim = '-' + t_prim\n",
    "        i -= 1\n",
    "    else:\n",
    "        t_prim = t[j-1] + t_prim\n",
    "        s_prim = '-' + s_prim\n",
    "        j -= 1\n",
    "\n",
    "print(s_prim)\n",
    "print(t_prim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63421162\n"
     ]
    }
   ],
   "source": [
    "# Counting Optimal Alignments (CTEA)\n",
    "# Returns the number of optimal edit alignments of strings v and w. \n",
    "\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "# Function to calculate the number of optimal edit alignments\n",
    "\n",
    "def ReadFASTA(filename):\n",
    "    seqs = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for record in SeqIO.parse(f, 'fasta'):\n",
    "            seqs.append(str(record.seq))\n",
    "    return seqs\n",
    "\n",
    "def count_alignment(v, w):\n",
    "    MOD = 134217727  # this is the Modulo value\n",
    "    \n",
    "    # Initialize matrices for edit distance and count of optimal alignments\n",
    "    n, m = len(v), len(w)\n",
    "    S = np.zeros((n + 1, m + 1), dtype=int)  # For edit distance scores\n",
    "    count = np.zeros((n + 1, m + 1), dtype=int)  # For counting the number of optimal alignments\n",
    "    \n",
    "    # Base case: first row and column\n",
    "    for i in range(n + 1):\n",
    "        S[i][0] = i\n",
    "        count[i][0] = 1\n",
    "    for j in range(1, m + 1):\n",
    "        S[0][j] = j\n",
    "        count[0][j] = 1\n",
    "    \n",
    "    # Fill the matrices using dynamic programming\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            # Calculate the costs for each possible operation\n",
    "            substitution_cost = S[i - 1][j - 1] + (v[i - 1] != w[j - 1])  # Substitution\n",
    "            insertion_cost = S[i - 1][j] + 1  # Deletion (insertion on the other string)\n",
    "            deletion_cost = S[i][j - 1] + 1  # Insertion (deletion on the other string)\n",
    "\n",
    "            # Choose the minimum cost\n",
    "            S[i][j] = min(substitution_cost, insertion_cost, deletion_cost)\n",
    "            \n",
    "            # Count the number of optimal alignments achieving the minimum score\n",
    "            if S[i][j] == substitution_cost:\n",
    "                count[i][j] += count[i - 1][j - 1]\n",
    "            if S[i][j] == insertion_cost:\n",
    "                count[i][j] += count[i - 1][j]\n",
    "            if S[i][j] == deletion_cost:\n",
    "                count[i][j] += count[i][j - 1]\n",
    "            \n",
    "            # Take the count modulo 134,217,727\n",
    "            count[i][j] %= MOD\n",
    "\n",
    "    return count[n][m]\n",
    "\n",
    "# Main code\n",
    "if __name__ == \"__main__\":\n",
    "    # Read sequences from the input file\n",
    "    seqs = ReadFASTA('rosalind_ctea.txt')\n",
    "    s, t = seqs[0], seqs[1]\n",
    "\n",
    "    # Get the number of optimal alignments\n",
    "    count = count_alignment(s, t)\n",
    "\n",
    "    # Print the result\n",
    "    print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1987\n"
     ]
    }
   ],
   "source": [
    "# I updated this code ! because I got an error last time \n",
    "# Global Alignment with Scoring Matrix\n",
    "#  GLOB \n",
    "# input two protein strings that should be imported in a fasta format \n",
    "# and I have to solve it via dynamic programming (fill in colomns and rows with gap penalty)\n",
    "# Output : the maximum allignment score \n",
    "\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"rosalind_glob.txt\"\n",
    "    sequence_name = []\n",
    "    sequence_string = []\n",
    "    with open(\"rosalind_glob.txt\", 'r') as f:\n",
    "        for record in SeqIO.parse(f, 'fasta'):\n",
    "            sequence_name.append(str(record.name))\n",
    "            sequence_string.append(str(record.seq))\n",
    "s, t = sequence_string # these are the two protein strings\n",
    "# then final output is global_alignment(s, t, scoring_matrix, gap_penalty)\n",
    "\n",
    "# Hint was loading BLOSUM62 Scoring Matrix: that was the built in to score matches and mismatches between two amino acids s and t\n",
    "# so in therminl I have to pip install blosum \n",
    "import blosum as bl \n",
    "# BLOSUM62\n",
    "matrix62 = bl.BLOSUM(62)\n",
    "val = matrix62[\"A\"][\"Y\"]\n",
    "\n",
    "gap_penalty = -5 # defining the gap penalty \n",
    "\n",
    "# now writing the dynamic programming table\n",
    "def global_alignment(s, t):\n",
    "    m = len(s)\n",
    "    n = len(t)\n",
    "    # initialization\n",
    "    dp_table = np.zeros((m + 1, n + 1), dtype=int)\n",
    "    # filling the first COLUMN just sum gap penalties\n",
    "    for i in range(1, m + 1):\n",
    "        dp_table[i][0] = dp_table[i - 1][0] + gap_penalty\n",
    "    # filling the first ROW just sum gap penalties\n",
    "    for j in range(1, n + 1):\n",
    "        dp_table[0][j] = dp_table[0][j - 1] + gap_penalty\n",
    "    \n",
    "# now dynamic programming to fill the table\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "\n",
    "            substitution = dp_table[i - 1][j - 1] + matrix62[s[i - 1]][t[j - 1]] # substitution score needs the matrix\n",
    "            insertion = dp_table[i][j - 1] + gap_penalty\n",
    "            deletion = dp_table[i - 1][j] + gap_penalty\n",
    "            # the maximum of substitution, insertion, deletion fills up the table\n",
    "            dp_table[i][j] = max(substitution, insertion, deletion)\n",
    "    return dp_table[m][n] # the absoultely last calue, in the right down would be the final answe\n",
    "\n",
    "print(global_alignment(s, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Jupiter Exercises : \n",
    "# Exersice 1 \n",
    "\n",
    "from random import randint\n",
    "from functools import reduce\n",
    "\n",
    "#generating random student dataset\n",
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student {i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "# again make a dictionary with students name and their average\n",
    "# instead here I have to use reduce to calculate the average \n",
    "\n",
    "students_with_averages = list(map(\n",
    "    lambda student: {\n",
    "        \"name\": student[\"name\"],\n",
    "        \"average_score\": reduce(lambda x, y: x + y, student[\"scores\"]) / len(student[\"scores\"])  #aclculating the averages mathematically\n",
    "    },\n",
    "    random_student_dataset\n",
    "))\n",
    "\n",
    "# filtering the students above the average score > 90 :\n",
    "top_students = list(filter(\n",
    "    lambda student: student[\"average_score\"] > 90,\n",
    "    students_with_averages\n",
    "))\n",
    "\n",
    "print(top_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exersice 2 : \n",
    "# hints: 1) Group products by category (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average price for each category and filter categories with an average price > 50\n",
    "\n",
    "from random import randint\n",
    "from functools import reduce\n",
    "#generating random product dataset\n",
    "def generate_random_product_dataset(num_products=100):\n",
    "    categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Product {i}\",\n",
    "            \"price\": randint(10, 200),  # Random price between 10 and 200\n",
    "            \"category\": choice(categories),  # Randomly choose a category\n",
    "        }\n",
    "        for i in range(1, num_products + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "random_dataset = generate_random_product_dataset(100)\n",
    "\n",
    "# AGain I have to build a dictionary to be able to access each element by its key\n",
    "# but I have make a function to group each in a list first \n",
    "# grouping by category (the key to the dictionay of grouped_by_category)\n",
    "def by_category(products):\n",
    "    grouped_by_category = {}\n",
    "    for product in products:\n",
    "        category = product[\"category\"]\n",
    "        if category not in grouped_by_category:\n",
    "            grouped_by_category[category] = []  # making an empty list\n",
    "        grouped_by_category[category].append(product)  # adding the products to the category\n",
    "    return grouped_by_category\n",
    "\n",
    "# now it's like exercise 1, I just put them togather by map and \n",
    "# calculate the average using reduce like accumulating it\n",
    "\n",
    "def category_with_averages(grouped_products):\n",
    "    category_averages = list(map(\n",
    "        lambda category: {\n",
    "            \"category\": category,\n",
    "            \"average_price\": reduce(lambda total, p: total + p[\"price\"], grouped_products[category], 0) / len(grouped_products[category])\n",
    "        },\n",
    "        grouped_products.keys()\n",
    "    ))\n",
    "    # now only show me the average price above 50\n",
    "    return list(filter(lambda cat: cat[\"average_price\"] > 50, category_averages))\n",
    "\n",
    "\n",
    "grouped_products = by_category(products)\n",
    "output = category_with_averages(grouped_products)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exersice 3: \n",
    "from random import randint\n",
    "from functools import reduce\n",
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold\n",
    "# your code goes here\n",
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold\n",
    "\n",
    "def generate_random_employee_dataset(num_employees=50):\n",
    "    departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Employee {i}\",\n",
    "            \"salary\": randint(40000, 120000),  # Random salary between 40,000 and 120,000\n",
    "            \"department\": choice(departments)  # Randomly choose a department\n",
    "        }\n",
    "        for i in range(1, num_employees + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "salaries = generate_random_employee_dataset(num_employees=50)\n",
    "\n",
    "# again I have to make a dictionary \n",
    "def grouping_employees_by_department(salaries):\n",
    "    grouped_by_department = {}\n",
    "    for salary in salaries:\n",
    "        department = salary[\"department\"]\n",
    "        if department not in grouped_by_department:\n",
    "            grouped_by_department[department] = [] \n",
    "        grouped_by_department[department].append(salary)  \n",
    "    return grouped_by_department\n",
    "\n",
    "grouped_salaries = grouping_employees_by_department(salaries)\n",
    "\n",
    "#calculate average salaries:\n",
    "# like above I can use map and reduce \n",
    "def filter_departments_by_average_salary(grouped_salaries):\n",
    "    department_averages = list(map(\n",
    "        lambda department: {\n",
    "            \"department\": department,\n",
    "            \"average_salary\": reduce(lambda total, p: total + p[\"salary\"], grouped_salaries[department], 0) / len(grouped_salaries[department])\n",
    "        },\n",
    "        grouped_salaries.keys()\n",
    "    ))\n",
    "    return list(filter(lambda dep: dep[\"average_salary\"] > 50, department_averages))\n",
    "#returns above 50 \n",
    "\n",
    "grouped_salaries = grouping_employees_by_department(salaries)\n",
    "output = filter_departments_by_average_salary(grouped_salaries)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4 : Biopython \n",
    "from Bio import pairwise2\n",
    "\n",
    "#1. **countMatches(s1, s2)**  \n",
    "#between aligned sequences\n",
    "def countMatches(s1, s2):\n",
    "    alignments = pairwise2.align.globalxx(s1, s2)\n",
    "    aligned_s1, aligned_s2 = alignments[0][0], alignments[0][1] \n",
    "    return sum(1 for a, b in zip(aligned_s1, aligned_s2) if a == b)\n",
    "\n",
    "#2: **countMismatches(s1, s2)**  \n",
    "#mismatched positions\n",
    "# so\n",
    "def countMismatches(s1, s2):\n",
    "    alignments = pairwise2.align.globalxx(s1, s2)\n",
    "    aligned_s1, aligned_s2 = alignments[0][0], alignments[0][1]\n",
    "    return sum(1 for a, b in zip(aligned_s1, aligned_s2) if a != b and a != '-' and b != '-')\n",
    "\n",
    "#3**countGapOpens(s1, s2)**: \n",
    "#gap openings\n",
    "#output is gap_opens += 1\n",
    "def countGapOpens(s1, s2):\n",
    "    alignments = pairwise2.align.globalxx(s1, s2)\n",
    "    aligned_s1, aligned_s2 = alignments[0][0], alignments[0][1]\n",
    "    gap_opens = 0\n",
    "    for a, b in zip(aligned_s1, aligned_s2):\n",
    "        if (a == '-' or b == '-') and not (aligned_s1[gap_opens - 1] == '-' or aligned_s2[gap_opens - 1] == '-'):\n",
    "            gap_opens += 1\n",
    "    return gap_opens\n",
    "\n",
    "\n",
    "#4:**countGapExtensions(s1, s2)** \n",
    "#ounting gap extensions\n",
    "#gap_extensions += 1\n",
    "def countGapExtensions(s1, s2):\n",
    "    alignments = pairwise2.align.globalxx(s1, s2)\n",
    "    aligned_s1, aligned_s2 = alignments[0][0], alignments[0][1]\n",
    "    gap_extensions = 0\n",
    "    in_gap = False\n",
    "    for a, b in zip(aligned_s1, aligned_s2):\n",
    "        if a == '-' or b == '-':\n",
    "            if in_gap:\n",
    "                gap_extensions += 1\n",
    "            else:\n",
    "                in_gap = True\n",
    "        else:\n",
    "            in_gap = False\n",
    "    return gap_extensions\n",
    "\n",
    "\n",
    "#5:**getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)**  \n",
    "# Calculating the alignment score based on a scoring scheme\n",
    "def getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty):\n",
    "    alignments = pairwise2.align.globalms(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)\n",
    "    return alignments[0][2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
