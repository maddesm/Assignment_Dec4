{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1732181925083,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "NZLKEFGqpkza"
   },
   "outputs": [],
   "source": [
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kMDITdMpkzc"
   },
   "source": [
    "# Map Reduce\n",
    "\n",
    "In the part of the assignment you are requested to use Map Reduce paradigm to solve the following exercises.\n",
    "\n",
    "**NOTE THAT**: **A solution that does not use map reduce is not valid!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UvFKq5Dpkzd"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "You have a list of dictionaries, each representing a student with the following properties: a name and an array of test scores. Your task is to use map, filter, and reduce to calculate the average test score for each student, and then return a list of dictionaries containing only the students whose average score is above 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnZxeOdtpkze"
   },
   "outputs": [],
   "source": [
    "students = [\n",
    "    {\"name\": \"Alice\", \"scores\": [95, 92, 88, 100]},\n",
    "    {\"name\": \"Bob\", \"scores\": [78, 81, 85, 80]},\n",
    "    {\"name\": \"Charlie\", \"scores\": [99, 91, 94, 96]},\n",
    "    {\"name\": \"Diana\", \"scores\": [85, 87, 89, 83]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WopOVxHSpkzf"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGYCqweYpkzf",
    "outputId": "89230ab4-a15a-4ae5-84a3-9eb13573a4a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Alice', 'average_score': 93.75},\n",
       " {'name': 'Charlie', 'average_score': 95.0}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"name\": \"Alice\", \"average_score\": 93.75},\n",
    "    {\"name\": \"Charlie\", \"average_score\": 95.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG5h3pN1pkzg"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1732181928585,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "3ZB3sFT_pkzh",
    "outputId": "cf486e14-4d6f-455d-8f69-19096dfe9831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Student 1', 'scores': [81, 93, 99, 80, 72]},\n",
       " {'name': 'Student 2', 'scores': [88, 68, 89, 98]},\n",
       " {'name': 'Student 3', 'scores': [95, 97, 59, 86]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student {i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "random_student_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHi3FLeWpkzi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Student 6', 'average_score': 91.75}, {'name': 'Student 32', 'average_score': 90.25}]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from functools import reduce\n",
    "\n",
    "#generating random student dataset\n",
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student {i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "# again make a dictionary with students name and their average\n",
    "# instead here I have to use reduce to calculate the average \n",
    "\n",
    "students_with_averages = list(map(\n",
    "    lambda student: {\n",
    "        \"name\": student[\"name\"],\n",
    "        \"average_score\": reduce(lambda x, y: x + y, student[\"scores\"]) / len(student[\"scores\"])  #aclculating the averages mathematically\n",
    "    },\n",
    "    random_student_dataset\n",
    "))\n",
    "\n",
    "# filtering the students above the average score > 90 :\n",
    "top_students = list(filter(\n",
    "    lambda student: student[\"average_score\"] > 90,\n",
    "    students_with_averages\n",
    "))\n",
    "\n",
    "print(top_students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWL_3xWNpkzj"
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "You have a list of dictionaries, each representing a product with the following properties: name, price, and category. Using the functions `map`, `filter`, and `reduce`, calculate the average price of the products in each category and return a list of dictionaries containing only the categories where the average price exceeds 50.\n",
    "\n",
    "Example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwk7f8Ihpkzk"
   },
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"name\": \"Product A\", \"price\": 60, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product B\", \"price\": 40, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product C\", \"price\": 70, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product D\", \"price\": 30, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product E\", \"price\": 90, \"category\": \"Sports\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agz3cP7Ppkzl"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbFtUV_apkzl",
    "outputId": "745cdcbe-7320-4a08-de7b-0e1bcb84473e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'Electronics', 'average_price': 50.0},\n",
       " {'category': 'Sports', 'average_price': 90.0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"category\": \"Electronics\", \"average_price\": 50.0},\n",
    "    {\"category\": \"Sports\", \"average_price\": 90.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKBEAQE3pkzl"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1732181933353,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "0qj_9nZSpkzm",
    "outputId": "7bab35c7-84d0-4603-a1da-dc4a76768179"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Product 1', 'price': 80, 'category': 'Home'},\n",
       " {'name': 'Product 2', 'price': 121, 'category': 'Electronics'},\n",
       " {'name': 'Product 3', 'price': 62, 'category': 'Clothing'},\n",
       " {'name': 'Product 4', 'price': 34, 'category': 'Toys'},\n",
       " {'name': 'Product 5', 'price': 30, 'category': 'Home'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_product_dataset(num_products=100):\n",
    "    categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Product {i}\",\n",
    "            \"price\": randint(10, 200),  # Random price between 10 and 200\n",
    "            \"category\": choice(categories),  # Randomly choose a category\n",
    "        }\n",
    "        for i in range(1, num_products + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "# Example of using the function\n",
    "random_dataset = generate_random_product_dataset(100)\n",
    "random_dataset[:5]  # Display the first 5 entries to check the dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG9V3Wt7pkzm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'category': 'Books', 'average_price': 107.22727272727273}, {'category': 'Electronics', 'average_price': 112.78947368421052}, {'category': 'Toys', 'average_price': 73.81818181818181}, {'category': 'Sports', 'average_price': 114.76190476190476}, {'category': 'Clothing', 'average_price': 95.16666666666667}, {'category': 'Home', 'average_price': 125.0}]\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group products by category (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average price for each category and filter categories with an average price > 50\n",
    "\n",
    "from random import randint\n",
    "from functools import reduce\n",
    "#generating random product dataset\n",
    "def generate_random_product_dataset(num_products=100):\n",
    "    categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Product {i}\",\n",
    "            \"price\": randint(10, 200),  # Random price between 10 and 200\n",
    "            \"category\": choice(categories),  # Randomly choose a category\n",
    "        }\n",
    "        for i in range(1, num_products + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "random_dataset = generate_random_product_dataset(100)\n",
    "\n",
    "# AGain I have to build a dictionary to be able to access each element by its key\n",
    "# but I have make a function to group each in a list first \n",
    "# grouping by category (the key to the dictionay of grouped_by_category)\n",
    "def by_category(products):\n",
    "    grouped_by_category = {}\n",
    "    for product in products:\n",
    "        category = product[\"category\"]\n",
    "        if category not in grouped_by_category:\n",
    "            grouped_by_category[category] = []  # making an empty list\n",
    "        grouped_by_category[category].append(product)  # adding the products to the category\n",
    "    return grouped_by_category\n",
    "\n",
    "# now it's like exercise 1, I just put them togather by map and \n",
    "# calculate the average using reduce like accumulating it\n",
    "\n",
    "def category_with_averages(grouped_products):\n",
    "    category_averages = list(map(\n",
    "        lambda category: {\n",
    "            \"category\": category,\n",
    "            \"average_price\": reduce(lambda total, p: total + p[\"price\"], grouped_products[category], 0) / len(grouped_products[category])\n",
    "        },\n",
    "        grouped_products.keys()\n",
    "    ))\n",
    "    # now only show me the average price above 50\n",
    "    return list(filter(lambda cat: cat[\"average_price\"] > 50, category_averages))\n",
    "\n",
    "\n",
    "grouped_products = by_category(products)\n",
    "output = category_with_averages(grouped_products)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hivtZEf7pkzm"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "You have a list of dictionaries, each representing an employee with the following properties: name, salary, and department. Your task is to use `map`, `filter`, and `reduce` to calculate the average salary for each department and return a list of dictionaries containing only the departments where the average salary is above 65,000.\n",
    "\n",
    "**Example Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1732181936402,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "N8vjLRHxpkzm"
   },
   "outputs": [],
   "source": [
    "employees = [\n",
    "    {\"name\": \"John\", \"salary\": 70000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Jane\", \"salary\": 75000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Alice\", \"salary\": 60000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Bob\", \"salary\": 68000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Charlie\", \"salary\": 90000, \"department\": \"Marketing\"},\n",
    "    {\"name\": \"Diana\", \"salary\": 50000, \"department\": \"Marketing\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otSniMO7pkzm"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Kx4HT8RXpkzn",
    "outputId": "8653ff13-815d-4040-c68e-fc4a6825134d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'department': 'Engineering', 'average_salary': 72500.0},\n",
       " {'department': 'Marketing', 'average_salary': 70000.0}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"department\": \"Engineering\", \"average_salary\": 72500.0},\n",
    "    {\"department\": \"Marketing\", \"average_salary\": 70000.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD_xlB78pkzn"
   },
   "source": [
    "### Test\n",
    "\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1732181939215,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "RhR9JLK-pkzn",
    "outputId": "72bc934d-4d3c-477e-cf84-3cf1d8fae61a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Employee 1', 'salary': 78950, 'department': 'IT'},\n",
       " {'name': 'Employee 2', 'salary': 49239, 'department': 'Engineering'},\n",
       " {'name': 'Employee 3', 'salary': 53845, 'department': 'IT'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_employee_dataset(num_employees=50):\n",
    "    departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Employee {i}\",\n",
    "            \"salary\": randint(40000, 120000),  # Random salary between 40,000 and 120,000\n",
    "            \"department\": choice(departments)  # Randomly choose a department\n",
    "        }\n",
    "        for i in range(1, num_employees + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_employee_dataset = generate_random_employee_dataset(50)\n",
    "\n",
    "random_employee_dataset[:3]  # Display the first 3 entries of each dataset for checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pt9m6NK-pkzo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'department': 'Engineering', 'average_salary': 86799.8}, {'department': 'Marketing', 'average_salary': 80054.66666666667}, {'department': 'Finance', 'average_salary': 78813.0}, {'department': 'IT', 'average_salary': 65661.0}, {'department': 'HR', 'average_salary': 80847.90909090909}, {'department': 'Sales', 'average_salary': 69762.2}]\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold\n",
    "# your code goes here\n",
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold\n",
    "\n",
    "def generate_random_employee_dataset(num_employees=50):\n",
    "    departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Employee {i}\",\n",
    "            \"salary\": randint(40000, 120000),  # Random salary between 40,000 and 120,000\n",
    "            \"department\": choice(departments)  # Randomly choose a department\n",
    "        }\n",
    "        for i in range(1, num_employees + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "salaries = generate_random_employee_dataset(num_employees=50)\n",
    "\n",
    "# again I have to make a dictionary \n",
    "def grouping_employees_by_department(salaries):\n",
    "    grouped_by_department = {}\n",
    "    for salary in salaries:\n",
    "        department = salary[\"department\"]\n",
    "        if department not in grouped_by_department:\n",
    "            grouped_by_department[department] = [] \n",
    "        grouped_by_department[department].append(salary)  \n",
    "    return grouped_by_department\n",
    "\n",
    "grouped_salaries = grouping_employees_by_department(salaries)\n",
    "\n",
    "#calculate average salaries:\n",
    "# like above I can use map and reduce \n",
    "def filter_departments_by_average_salary(grouped_salaries):\n",
    "    department_averages = list(map(\n",
    "        lambda department: {\n",
    "            \"department\": department,\n",
    "            \"average_salary\": reduce(lambda total, p: total + p[\"salary\"], grouped_salaries[department], 0) / len(grouped_salaries[department])\n",
    "        },\n",
    "        grouped_salaries.keys()\n",
    "    ))\n",
    "    return list(filter(lambda dep: dep[\"average_salary\"] > 50, department_averages))\n",
    "#returns above 50 \n",
    "\n",
    "grouped_salaries = grouping_employees_by_department(salaries)\n",
    "output = filter_departments_by_average_salary(grouped_salaries)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzxr0v2Rpkzo"
   },
   "source": [
    "# Biopython\n",
    "\n",
    "Write the following five functions to analyze global alignments between two sequences using Biopython's `pairwise2` module:\n",
    "\n",
    "1. **countMatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment (pairwise2.globalxx) of the same length. It returns the number of positions where the elements of both sequences match.\n",
    "\n",
    "2. **countMismatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of positions where the elements of the two sequences are different (i.e., they are not gaps, and the characters do not match).\n",
    "\n",
    "3. **countGapOpens(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap openings in the alignment (a gap is opened when a '-' appears in the sequence).\n",
    "\n",
    "4. **countGapExtensions(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap extensions (where '-' continues in the alignment after an initial gap is opened).\n",
    "\n",
    "5. **getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment and returns the alignment score based on the provided scoring scheme: `matchScore` for matches, `mismatchPenalty` for mismatches, `gapOpenPenalty` for opening a gap, and `gapExtensionPenalty` for extending a gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5PIaf6BUpkzo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Bio import pairwise2\n",
    "\n",
    "#1. **countMatches(s1, s2)**  \n",
    "#between aligned sequences\n",
    "def countMatches(s1, s2):\n",
    "    alignments = pairwise2.align.globalxx(s1, s2)\n",
    "    aligned_s1, aligned_s2 = alignments[0][0], alignments[0][1] \n",
    "    return sum(1 for a, b in zip(aligned_s1, aligned_s2) if a == b)\n",
    "\n",
    "#2: **countMismatches(s1, s2)**  \n",
    "#mismatched positions\n",
    "# so\n",
    "def countMismatches(s1, s2):\n",
    "    alignments = pairwise2.align.globalxx(s1, s2)\n",
    "    aligned_s1, aligned_s2 = alignments[0][0], alignments[0][1]\n",
    "    return sum(1 for a, b in zip(aligned_s1, aligned_s2) if a != b and a != '-' and b != '-')\n",
    "\n",
    "#3**countGapOpens(s1, s2)**: \n",
    "#gap openings\n",
    "#output is gap_opens += 1\n",
    "def countGapOpens(s1, s2):\n",
    "    alignments = pairwise2.align.globalxx(s1, s2)\n",
    "    aligned_s1, aligned_s2 = alignments[0][0], alignments[0][1]\n",
    "    gap_opens = 0\n",
    "    for a, b in zip(aligned_s1, aligned_s2):\n",
    "        if (a == '-' or b == '-') and not (aligned_s1[gap_opens - 1] == '-' or aligned_s2[gap_opens - 1] == '-'):\n",
    "            gap_opens += 1\n",
    "    return gap_opens\n",
    "\n",
    "\n",
    "#4:**countGapExtensions(s1, s2)** \n",
    "#ounting gap extensions\n",
    "#gap_extensions += 1\n",
    "def countGapExtensions(s1, s2):\n",
    "    alignments = pairwise2.align.globalxx(s1, s2)\n",
    "    aligned_s1, aligned_s2 = alignments[0][0], alignments[0][1]\n",
    "    gap_extensions = 0\n",
    "    in_gap = False\n",
    "    for a, b in zip(aligned_s1, aligned_s2):\n",
    "        if a == '-' or b == '-':\n",
    "            if in_gap:\n",
    "                gap_extensions += 1\n",
    "            else:\n",
    "                in_gap = True\n",
    "        else:\n",
    "            in_gap = False\n",
    "    return gap_extensions\n",
    "\n",
    "\n",
    "#5:**getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)**  \n",
    "# Calculating the alignment score based on a scoring scheme\n",
    "def getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty):\n",
    "    alignments = pairwise2.align.globalms(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)\n",
    "    return alignments[0][2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81O19v1fpkzo"
   },
   "source": [
    "### Test\n",
    "Align the sequences of the [Interleukin-12](https://en.wikipedia.org/wiki/Interleukin_12) chain A (denoted as `s1`) from the file [`IL12A.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12A.fasta) and the Interleukin-12 chain B (denoted as `s2`) from the file [`IL12B.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12B.fasta) and check the score as computed from pairwise2 and from your functions."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
